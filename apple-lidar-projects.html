<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Current Apple LiDAR Projects on GitHub</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 20px;
            max-width: 800px;
            margin: auto;
            color: #333;
        }
        h1, h2 {
            color: #0066cc;
        }
        ul {
            margin-left: 20px;
        }
        footer {
            margin-top: 20px;
            font-size: 0.9em;
            text-align: center;
            color: #666;
        }
        .project-link {
            color: #0066cc;
            text-decoration: none;
        }
        .project-link:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Current Apple LiDAR Projects on GitHub</h1>
    <p>Below is a curated list of open-source projects that utilize Apple's LiDAR technology, along with their respective licenses:</p>
    
    <h2>1. meshARment</h2>
    <p><strong>Description:</strong> A Unity project that utilizes the LiDAR sensor in newer Apple devices to measure distances and inclines, particularly useful for construction sites and surface assessments.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/Eternoxy/meshARment" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>2. iOS LiDar Scanner Realtime with TouchDesigner</h2>
    <p><strong>Description:</strong> An application demonstrating real-time LiDAR scanning on iOS devices, streaming data to TouchDesigner for visualization and further processing.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/gwangyu-lee/iOS-LiDar-Scanner-Realtime-with-TouchDesigner" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>3. iLiDAR</h2>
    <p><strong>Description:</strong> A project that transforms an iPhone into a multi-modality visual sensor, integrating LiDAR and RGB cameras to capture and synchronize real-time data with a PC.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/Galaxywalk/iLiDAR" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>4. ExampleOfiOSLiDAR</h2>
    <p><strong>Description:</strong> Sample code utilizing iOS ARKit's LiDAR capabilities, featuring functionalities like depth mapping, confidence mapping, collision detection, and exporting scanned objects to .obj files.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/TokyoYoshida/ExampleOfiOSLiDAR" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>5. 3D Scanner LiDAR</h2>
    <p><strong>Description:</strong> An iOS application designed for iPad models equipped with LiDAR sensors, enabling the creation of 3D representations of real-world features.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/anish-sekar/3D-scanner-LiDAR" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>6. ios-lidar-mesh</h2>
    <p><strong>Description:</strong> A project demonstrating how ARKit uses the LiDAR scanner to create a polygonal model of the physical environment, facilitating accurate real-world shape estimation without user movement.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/ximhear/ios-lidar-mesh" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>7. LiDAR Depth Map Capture for iOS</h2>
    <p><strong>Description:</strong> An iOS app that captures full-resolution, 32-bit floating-point depth maps using the LiDAR scanner, preserving original precision for professional use.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/ioridev/LiDAR-Depth-Map-Capture-for-iOS" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>8. arkit-scenedepth-pointcloud</h2>
    <p><strong>Description:</strong> An iOS example app that generates point clouds in ARKit using scene depth, providing a foundation for depth-based visualizations.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/isakdiaz/arkit-scenedepth-pointcloud" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>9. Rcam3</h2>
    <p><strong>Description:</strong> A real-time VFX project utilizing the iPhone LiDAR sensor and Unity VFX Graph, comprising an iPhone app for scene capture and a host machine visualizer for rendering.</p>
    <p><strong>License:</strong> Unlicense</p>
    <p><a href="https://github.com/keijiro/Rcam3" class="project-link" target="_blank">View on GitHub</a></p>
    
    <h2>10. VisualizingAPointCloudUsingSceneDepth</h2>
    <p><strong>Description:</strong> A sample code project that places points in the real world using scene depth data to visualize the physical environment's shape, associated with WWDC20 session 10611.</p>
    <p><strong>License:</strong> MIT License</p>
    <p><a href="https://github.com/suzuki-naoto/VisualizingAPointCloudUsingSceneDepth" class="project-link" target="_blank">View on GitHub</a></p>
    
    <footer>
        <p>This page is licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank">Creative Commons CC0</a>.</p>
    </footer>
</body>
</html>
